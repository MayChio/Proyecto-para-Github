#!/usr/bin/env python
# coding: utf-8

# 
# 
# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# He revisado tu proyecto y quiero informarte que los datos necesarios los puedes encontrar en el siguiente path: /datasets/final_provider/. Es fundamental que sigas tu plan de proyecto, ya que este es un proyecto que se puede resolver mediante clasificaci√≥n. Ser√° necesario que identifiques la variable objetivo o que la crees si a√∫n no lo has hecho. Te sugiero que observes la variable que indica si un cliente finaliz√≥ su contrato. De esta forma, podremos predecir si un cliente cancelar√° o no su contrato.
# 
# ¬°Buen trabajo hasta ahora y sigue adelante con el proyecto!
# 
# 
# √Ånimo, estoy seguro de que vas por un muy buen camino.
# 
# 
# Gracias por tu trabajo. &#128077;
#     
# </div>
# 

# # INTRODUCCI√ìN 

# <div class="alert alert-block alert-info">
#   <p>En el competitivo sector de las telecomunicaciones, la retenci√≥n de clientes es un factor crucial para mantener la estabilidad y el crecimiento de una empresa. Interconnect, un operador de telecomunicaciones bajo la compa√±√≠a Telecom Al, se enfrenta al desaf√≠o de pronosticar la tasa de cancelaci√≥n de sus clientes. Este conocimiento es vital, ya que permite a la empresa identificar a aquellos usuarios que podr√≠an estar considerando cambiar de proveedor. Al anticipar estas cancelaciones, Interconnect tiene la oportunidad de ofrecer c√≥digos promocionales y opciones de planes especiales, con el objetivo de retener a estos clientes y reducir la tasa de abandono.
# 
# Interconnect ofrece una gama de servicios, principalmente en dos √°reas: comunicaci√≥n por tel√©fono fijo e internet. Los clientes pueden acceder a servicios de telefon√≠a que permiten la conexi√≥n simult√°nea a varias l√≠neas, as√≠ como a internet a trav√©s de DSL o fibra √≥ptica. Adem√°s, la empresa proporciona otros servicios complementarios, como seguridad en internet mediante software antivirus y bloqueadores de sitios web maliciosos, soporte t√©cnico especializado, almacenamiento en la nube, backup de datos, y servicios de streaming de TV y pel√≠culas.
# 
# Con una oferta tan diversa, la capacidad de entender el comportamiento y las necesidades de los clientes se vuelve indispensable para mantener la lealtad del consumidor. El equipo de marketing de Interconnect ha recopilado una valiosa base de datos que incluye informaci√≥n sobre los planes y contratos de sus clientes, lo que permitir√° a la empresa desarrollar un modelo predictivo de cancelaci√≥n. Este modelo no solo contribuir√° a mejorar la retenci√≥n de clientes, sino que tambi√©n fortalecer√° las estrategias comerciales de Interconnect en un mercado altamente competitivo</p>
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b>
# <p>Tu introducci√≥n establece claramente la importancia de la retenci√≥n de clientes en el sector de las telecomunicaciones y c√≥mo Interconnect busca abordar este desaf√≠o. Sin embargo, ser√≠a √∫til conectar m√°s expl√≠citamente c√≥mo la recopilaci√≥n de datos y el modelado predictivo que has mencionado encajar√°n en el flujo general del proyecto. Esto ayudar√° a los lectores a entender mejor la transici√≥n entre la introducci√≥n y las siguientes secciones del informe.</p>
# </div>
# 

# ## DESCRIPCI√ìN DE LOS DATOS 

# <div class="alert alert-block alert-info">
#   <p>Los datos consisten en archivos obtenidos de diferentes fuentes:
# 
# - `contract.csv` ‚Äî informaci√≥n del contrato;
# - `personal.csv` ‚Äî datos personales del cliente;
# - `internet.csv` ‚Äî informaci√≥n sobre los servicios de Internet;
# - `phone.csv` ‚Äî informaci√≥n sobre los servicios telef√≥nicos.
# 
# En cada archivo, la columna `customerID` (ID de cliente) contiene un c√≥digo √∫nico asignado a cada cliente. La informaci√≥n del contrato es v√°lida a partir del 1 de febrero de 2020.</p>
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b>
# <p>La descripci√≥n de los datos es concisa y cubre los aspectos esenciales de las fuentes de datos utilizadas. Considera a√±adir una breve explicaci√≥n de c√≥mo planeas utilizar cada uno de estos conjuntos de datos en el an√°lisis y modelado. Esto proporcionar√° un contexto adicional y facilitar√° la comprensi√≥n de su relevancia en el proyecto.</p>
# </div>
# 

# In[19]:


#Imporrtar librer√≠as 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


# In[20]:


#Definir ruta de archivo 
df = pd.read_csv("/datasets/final_provider/contract.csv")
display(df)


# ### Preparaci√≥n del entorno de datos 

# In[21]:


# Convertir TotalCharges a num√©rico
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Verificar la conversi√≥n y contar valores nulos
nulos_totalcharges = df['TotalCharges'].isnull().sum()
print(f'N√∫mero de valores nulos en TotalCharges: {nulos_totalcharges}')


# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b>
# <p>Podr√≠as detallar m√°s sobre por qu√© elegiste ciertas t√©cnicas de imputaci√≥n para valores faltantes. Por ejemplo, explicar por qu√© decidiste imputar con la media o la mediana en lugar de otras t√©cnicas podr√≠a proporcionar un entendimiento m√°s profundo del enfoque.</p>
# </div>
# 

# #### Verificar valores NAN o infinitos 

# In[22]:


# Verificar NaN o infinitos en las caracter√≠sticas
print("Valores NaN en X_train:", np.any(np.isnan(X_train)))
print("Valores infinitos en X_train:", np.any(np.isinf(X_train)))

# Verificar NaN o infinitos en la variable objetivo
print("Valores NaN en y_train:", np.any(np.isnan(y_train)))
print("Valores infinitos en y_train:", np.any(np.isinf(y_train)))

# Eliminar o imputar valores NaN o infinitos
X_train = np.nan_to_num(X_train, nan=np.nanmean(X_train))
X_test = np.nan_to_num(X_test, nan=np.nanmean(X_test))

# Confirmar que no haya valores NaN o infinitos
print("Valores NaN en X_train despu√©s de la limpieza:", np.any(np.isnan(X_train)))
print("Valores infinitos en X_train despu√©s de la limpieza:", np.any(np.isinf(X_train)))


# In[25]:


# Convertir y_train en un DataFrame si es necesario
if isinstance(y_train, np.ndarray):
    y_train = pd.Series(y_train)

# Contar valores NaN en y_train
num_nan = y_train.isna().sum()
print(f"N√∫mero de valores NaN en y_train: {num_nan}")

# Verificar la proporci√≥n de valores NaN
total_values = y_train.shape[0]
proporcion_nan = num_nan / total_values
print(f"Proporci√≥n de valores NaN en y_train: {proporcion_nan:.2%}")


# #### Imputar valores NAN 

# In[26]:


# Imputar valores NaN en y_train con la media
media_y_train = y_train.mean()
y_train_imputado = y_train.fillna(media_y_train)

# Verificar que no haya valores NaN en y_train despu√©s de la imputaci√≥n
print("Valores NaN en y_train despu√©s de la imputaci√≥n:", y_train_imputado.isna().sum())


# In[27]:


# Imputar valores NaN en y_train con la mediana
mediana_y_train = y_train.median()
y_train_imputado = y_train.fillna(mediana_y_train)

# Verificar que no haya valores NaN en y_train despu√©s de la imputaci√≥n
print("Valores NaN en y_train despu√©s de la imputaci√≥n:", y_train_imputado.isna().sum())


# ### An√°lisis Exploratorio de Datos (EDA)

# In[28]:


# 1. Revisi√≥n inicial de los datos
print("Primeras filas del dataframe:")
print(df.head())

print("\n√öltimas filas del dataframe:")
print(df.tail())

print("\nDimensiones del dataframe:")
print(df.shape)

print("\nTipos de datos de cada columna:")
print(df.dtypes)

print("\nValores nulos en cada columna:")
print(df.isnull().sum())

# 2. Estad√≠sticas descriptivas
print("\nEstad√≠sticas descriptivas de las variables num√©ricas:")
print(df.describe())

print("\nDistribuci√≥n de las variables categ√≥ricas:")
print(df.describe(include='object'))

# 3. Detecci√≥n de valores duplicados
print("\nN√∫mero de filas duplicadas:")
print(df.duplicated().sum())

# 4. An√°lisis de correlaci√≥n
print("\nMatriz de correlaci√≥n:")
correlation_matrix = df.corr()
print(correlation_matrix)

plt.figure(figsize=(10,8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Heatmap de la correlaci√≥n entre variables num√©ricas")
plt.show()


# <div class="alert alert-block alert-info">
#   <p>1. Revisi√≥n Inicial de los Datos:
# 
# Al revisar las primeras y √∫ltimas filas del dataframe, observo que el conjunto de datos contiene informaci√≥n sobre contratos de clientes, como la fecha de inicio y fin del contrato, el tipo de contrato, el m√©todo de pago, entre otros. Las columnas clave incluyen customerID, BeginDate, EndDate, Type, PaperlessBilling, PaymentMethod, MonthlyCharges, y TotalCharges. Estas columnas nos proporcionan un panorama general de los servicios que los clientes han contratado, sus m√©todos de pago, y los cargos mensuales.
# 
# El dataframe tiene 7043 filas y 8 columnas, lo que sugiere que estamos trabajando con una muestra considerable de datos.
# 
# 2. Tipos de Datos:
# 
# Al analizar los tipos de datos, not√© que las columnas MonthlyCharges est√°n correctamente almacenadas como valores num√©ricos (float64), lo que es ideal para an√°lisis estad√≠sticos. Sin embargo, TotalCharges, que deber√≠a ser num√©rica, est√° almacenada como un tipo de dato object. Esto sugiere que puede haber valores no num√©ricos o vac√≠os en esta columna que necesitan ser corregidos antes de cualquier an√°lisis cuantitativo.
# 
# 3. Valores Nulos:
# 
# No se detectaron valores nulos en ninguna de las columnas del dataframe, lo que es un aspecto positivo y sugiere que los datos est√°n relativamente completos. Sin embargo, es importante revisar los valores en la columna TotalCharges m√°s de cerca, ya que el tipo de dato object podr√≠a estar ocultando inconsistencias.
# 
# 4. Estad√≠sticas Descriptivas:
# 
# Para la columna MonthlyCharges, el an√°lisis muestra un cargo mensual promedio de $64.76 con un rango de valores entre $18.25 y $118.75. Esto sugiere una amplia variabilidad en los cargos mensuales que los clientes est√°n pagando, posiblemente dependiendo de los servicios contratados.
# 
# En cuanto a las variables categ√≥ricas:
# 
# La columna Type muestra que la mayor√≠a de los clientes est√°n en un contrato "Month-to-month", lo que indica flexibilidad para los clientes y un mayor riesgo de cancelaci√≥n.
# El m√©todo de pago m√°s com√∫n es Electronic check, seguido por otros m√©todos como Mailed check, Bank transfer, y Credit card.
# La columna TotalCharges tiene 6531 valores √∫nicos, con un valor m√°s frecuente que aparece 11 veces, lo que nuevamente sugiere que puede haber valores que necesitan una limpieza o transformaci√≥n.
# 5. Detecci√≥n de Valores Duplicados:
# 
# No se encontraron filas duplicadas, lo que indica que cada registro en el dataset es √∫nico, basado en el customerID.
# 
# 6. An√°lisis de Correlaci√≥n:
# 
# El an√°lisis de correlaci√≥n fue limitado ya que solo la columna MonthlyCharges es num√©rica. No se observa ninguna correlaci√≥n m√∫ltiple en esta parte del an√°lisis. Este resultado confirma que no hay relaciones directas entre las variables num√©ricas en este dataset espec√≠fico, pero esto puede cambiar una vez que transformemos la columna TotalCharges en un tipo num√©rico.
# 
# Esta exploraci√≥n inicial me ha dado una comprensi√≥n b√°sica del dataset. El siguiente paso ser√° transformar la columna TotalCharges en un tipo num√©rico y manejar cualquier valor no v√°lido. Luego, podr√© proceder a un an√°lisis m√°s detallado y a preparar los datos para modelado.</p>
# </div>

# In[29]:


# Distribuci√≥n de MonthlyCharges
plt.figure(figsize=(10, 6))
sns.histplot(df['MonthlyCharges'], bins=30, kde=True)
plt.title('Distribuci√≥n de Cargos Mensuales')
plt.xlabel('Cargos Mensuales')
plt.ylabel('Frecuencia')
plt.show()

# Distribuci√≥n de TotalCharges
plt.figure(figsize=(10, 6))
sns.histplot(df['TotalCharges'], bins=30, kde=True)
plt.title('Distribuci√≥n de Cargos Totales')
plt.xlabel('Cargos Totales')
plt.ylabel('Frecuencia')
plt.show()

# An√°lisis de contratos por tipo
plt.figure(figsize=(10, 6))
sns.countplot(x='Type', data=df)
plt.title('N√∫mero de Contratos por Tipo')
plt.xlabel('Tipo de Contrato')
plt.ylabel('N√∫mero de Clientes')
plt.show()


# ### Preparaci√≥n para el modelo 

# In[30]:


# Codificaci√≥n de variables categ√≥ricas
df_encoded = pd.get_dummies(df, columns=['Type', 'PaperlessBilling', 'PaymentMethod'])

# Separar caracter√≠sticas y variable objetivo
X = df_encoded.drop(['customerID', 'BeginDate', 'EndDate', 'TotalCharges'], axis=1)
y = df_encoded['TotalCharges']  # Asumiendo que quieres predecir TotalCharges

# Normalizaci√≥n si es necesario
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


# #### Revisar separamiento de datos 

# In[31]:


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Verificar dimensiones de los conjuntos
print(f"Dimensiones de X_train: {X_train.shape}")
print(f"Dimensiones de X_test: {X_test.shape}")
print(f"Dimensiones de y_train: {y_train.shape}")
print(f"Dimensiones de y_test: {y_test.shape}")


# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b>
# <p>La preparaci√≥n para el modelo est√° bien estructurada, con un enfoque claro en la codificaci√≥n de variables categ√≥ricas y la normalizaci√≥n. Ser√≠a beneficioso explicar por qu√© seleccionaste el modelo. Esta explicaci√≥n ayudar√° a justificar las decisiones tomadas en esta etapa.</p>
# </div>
# 

# ### Entrenamiento del modelo  

# In[34]:


import numpy as np

# Verificar valores NaN e infinitos en y_test
print("Valores NaN en y_test:", np.isnan(y_test).sum())
print("Valores infinitos en y_test:", np.isinf(y_test).sum())

# Verificar valores NaN e infinitos en y_pred
print("Valores NaN en y_pred:", np.isnan(y_pred).sum())
print("Valores infinitos en y_pred:", np.isinf(y_pred).sum())


# In[35]:


import numpy as np

# Eliminar filas con valores NaN en y_test y sus correspondientes en y_pred
valid_indices = ~np.isnan(y_test)
y_test_valid = y_test[valid_indices]
y_pred_valid = y_pred[valid_indices]

# Verificar despu√©s de limpiar
print("Valores NaN en y_test_valid:", np.isnan(y_test_valid).sum())
print("Valores infinitos en y_test_valid:", np.isinf(y_test_valid).sum())
print("Valores NaN en y_pred_valid:", np.isnan(y_pred_valid).sum())
print("Valores infinitos en y_pred_valid:", np.isinf(y_pred_valid).sum())


# In[38]:


#Revaluar el modelo 
from sklearn.metrics import mean_squared_error, r2_score

# Evaluar el modelo
print('Mean Squared Error:', mean_squared_error(y_test_valid, y_pred_valid))
print('R-squared:', r2_score(y_test_valid, y_pred_valid))


# <div class="alert alert-block alert-info">
#   <p>Mean Squared Error (MSE):
# 
# Valor: 1,617,700.76
# Interpretaci√≥n: El MSE representa el promedio de los cuadrados de los errores, es decir, la diferencia promedio entre las predicciones y los valores reales al cuadrado. Un valor m√°s bajo indica una mejor precisi√≥n del modelo, pero no tienes una referencia directa para saber si este valor es bueno o malo sin compararlo con alg√∫n est√°ndar o con el desempe√±o de otros modelos.
# R-squared (R¬≤):
# 
# Valor: 0.689
# Interpretaci√≥n: El R¬≤ es una medida de cu√°nto var√≠a la variable dependiente a partir de la variable independiente. Un valor de 0.689 sugiere que aproximadamente el 68.9% de la variabilidad en la variable dependiente puede ser explicada por el modelo. Esto indica una buena capacidad predictiva del modelo, aunque a√∫n hay margen para mejorar.</p>
# </div>

# <div class="alert alert-block alert-info">
#   <p>Con los valores limpios, el desempe√±o del modelo Ridge es:
# 
# Mean Squared Error (MSE): 1,617,620.56
# R-squared: 0.6891
# Estos resultados muestran que el modelo Ridge tiene un MSE ligeramente m√°s bajo y un R-squared casi igual al modelo base. Ambos modelos parecen tener un rendimiento similar, lo que puede indicar que la diferencia entre ellos es peque√±a en este caso. Si la diferencia no es significativa para tus objetivos, podr√≠as elegir el modelo que prefieras bas√°ndote en otros criterios, como la simplicidad del modelo, la interpretabilidad, o el tiempo de entrenamiento.</p>
# </div>

# # DOCUMENTAR RESULTADOS 

# <div class="alert alert-block alert-info">
#   <p>Modelo Base
# Evaluaci√≥n del Modelo Base:
# 
# Mean Squared Error (MSE):
# Valor: 1617700.7605912231
# R-squared (R¬≤):
# Valor: 0.6890536211156914
# Notas:
# 
# El MSE indica el promedio de los errores cuadrados. Un MSE m√°s bajo es mejor.
# El R-squared representa la proporci√≥n de la variabilidad en la variable dependiente que es explicada por el modelo. Un R¬≤ m√°s cercano a 1 indica un mejor ajuste.
# Modelo Ridge (limpio)
# Evaluaci√≥n del Modelo Ridge (despu√©s de limpieza):
# 
# Mean Squared Error (MSE):
# Valor: 1617620.55895689
# R-squared (R¬≤):
# Valor: 0.6890690370741825
# Notas:
# 
# El MSE y R¬≤ del modelo Ridge despu√©s de la limpieza son muy similares a los del modelo base, indicando que la limpieza de datos no ha tenido un impacto significativo en el rendimiento del modelo.</p>
# </div>

# ## COMPARACI√ìN DE MODELOS 

# <div class="alert alert-block alert-info">
#   <p>Resumen:
# 
# Ambos modelos, el base y el Ridge, muestran resultados similares en cuanto al MSE y R-squared.
# La limpieza de datos ha mostrado una ligera mejora en los valores del MSE y R¬≤, pero la diferencia no es significativa.
#       
#       
#       
# Conclusi√≥n:
# 
# Dado que ambos modelos tienen un rendimiento similar, podr√≠as elegir el modelo Ridge si prefieres utilizar t√©cnicas de regularizaci√≥n para evitar sobreajuste. Sin embargo, la elecci√≥n final puede depender de otros factores como la simplicidad del modelo o los requisitos espec√≠ficos del proyecto.</p>
# </div>

# # INFORME SOLUCI√ìN 

# <div class="alert alert-block alert-info">
#   <p>1. Resumen del Proyecto
#       
#       
#       
# El objetivo de este proyecto fue desarrollar y evaluar modelos de regresi√≥n para predecir una variable continua a partir de un conjunto de datos. Se realizaron varias etapas, incluyendo la limpieza de datos, la selecci√≥n y entrenamiento de modelos, y la evaluaci√≥n de su rendimiento.</p>
# </div>

# <div class="alert alert-block alert-info">
#   <p>2. Pasos del Plan Realizados y Omitidos
# Pasos Realizados:
# 
# Preprocesamiento de Datos:
# 
# Identificaci√≥n y manejo de valores faltantes en el conjunto de datos.
# Limpieza y preparaci√≥n de datos para el entrenamiento.
# Selecci√≥n y Entrenamiento de Modelos:
# 
# Entrenamiento del modelo base de regresi√≥n lineal.
# Entrenamiento del modelo Ridge para comparaci√≥n.
# Evaluaci√≥n del Rendimiento:
# 
# Evaluaci√≥n del rendimiento de los modelos utilizando m√©tricas como el Mean Squared Error (MSE) y el R-squared (R¬≤).
# Comparaci√≥n entre el modelo base y el modelo Ridge.
# Pasos Omitidos:
# 
# Modelos Adicionales: No se incluyeron modelos adicionales m√°s all√° de la regresi√≥n lineal y Ridge debido a restricciones de tiempo y la similitud en los resultados observados.</p>
# </div>

# <div class="alert alert-block alert-info">
#   <p>3. Dificultades Encontradas y Soluciones
# Dificultades:
# 
# Valores Faltantes:
# 
# Se identificaron valores NaN en la variable dependiente (y_train). Esto gener√≥ errores al entrenar y evaluar los modelos.
# Soluci√≥n:
# 
# Se opt√≥ por eliminar las filas con valores faltantes en y_train, ya que representaban una peque√±a fracci√≥n del total de los datos (0.18%).
# Errores en Evaluaci√≥n de Modelos:
# 
# Durante la evaluaci√≥n del modelo Ridge, se encontraron errores relacionados con valores NaN en los datos de entrada.
# Soluci√≥n:
# 
# Se revisaron y limpiaron los datos, asegurando que no hubiera valores NaN o infinitos antes de realizar la evaluaci√≥n final.</p>
# </div>

# <div class="alert alert-block alert-info">
#   <p>4. Pasos Clave para Resolver la Tarea
# Limpieza de Datos:
# 
# Identificaci√≥n y manejo de valores faltantes y errores en los datos para asegurar que el conjunto de datos sea adecuado para el modelado.
# Entrenamiento y Evaluaci√≥n de Modelos:
# 
# Entrenamiento de un modelo base y un modelo Ridge, seguido de una evaluaci√≥n rigurosa utilizando m√©tricas de rendimiento para comparar y seleccionar el modelo adecuado.</p>
# </div>

# <div class="alert alert-block alert-info">
#   <p>5. Modelo Final y Nivel de Calidad
# Modelo Final:
# 
# Modelo Ridge (despu√©s de limpieza)
# Rendimiento del Modelo:
# 
# Mean Squared Error (MSE): 1617620.55895689
# R-squared (R¬≤): 0.6890690370741825
# Nivel de Calidad:
# 
# El rendimiento del modelo Ridge es comparable al del modelo base, con una ligera mejora en las m√©tricas de evaluaci√≥n. Ambos modelos muestran un nivel de ajuste razonable con un R¬≤ de aproximadamente 0.689, lo que indica que el modelo es capaz de explicar cerca del 69% de la variabilidad en los datos.</p>
# </div>

# ## CONCLUSI√ìN 1 

# <div class="alert alert-block alert-info">
#   <p>El modelo final, Ridge, ha sido seleccionado por su capacidad para manejar la regularizaci√≥n, lo que puede ser beneficioso en escenarios m√°s complejos. La calidad del modelo es adecuada y se ha logrado un buen ajuste con los datos disponibles.</p>
# </div>

# ## CONCLUSI√ìN DEL PROYECTO 

# <div class="alert alert-block alert-info">
#   <p>El proyecto ha consistido en el desarrollo y evaluaci√≥n de modelos de regresi√≥n para predecir una variable continua utilizando un conjunto de datos complejo. A lo largo del proceso, se han llevado a cabo varias etapas cr√≠ticas, desde la limpieza y preparaci√≥n de datos hasta la selecci√≥n y comparaci√≥n de modelos de regresi√≥n.
# 
# **1. Limpieza de Datos:
# 
# Se identificaron y resolvieron problemas de datos faltantes en la variable dependiente (y_train), lo que permiti√≥ una preparaci√≥n adecuada del conjunto de datos para el modelado. La decisi√≥n de eliminar las filas con valores NaN fue fundamentada, dado que representaban una fracci√≥n menor del total de los datos (0.18%). Este enfoque garantiz√≥ que los modelos entrenados no se viesen afectados negativamente por datos incompletos.
# **2. Selecci√≥n y Entrenamiento de Modelos:
# 
# Se entrenaron dos modelos de regresi√≥n: un modelo base de regresi√≥n lineal y un modelo Ridge. La regresi√≥n Ridge se eligi√≥ por su capacidad para manejar la regularizaci√≥n, que es beneficiosa cuando se enfrentan problemas de sobreajuste en modelos complejos.
# **3. Evaluaci√≥n del Rendimiento:
# 
# Ambos modelos se evaluaron utilizando el Mean Squared Error (MSE) y el R-squared (R¬≤). Los resultados mostraron que el modelo Ridge ofreci√≥ una ligera mejora en comparaci√≥n con el modelo base, con un MSE de 1617620.55895689 y un R¬≤ de 0.6890690370741825. Estos valores indican un buen nivel de ajuste, con el modelo explicando aproximadamente el 69% de la variabilidad en los datos de prueba.
# **4. Dificultades y Resoluci√≥n:
# 
# Se enfrentaron problemas relacionados con valores NaN durante el entrenamiento y evaluaci√≥n de los modelos. La soluci√≥n consisti√≥ en revisar y limpiar los datos minuciosamente para asegurar que todos los datos utilizados en el entrenamiento y evaluaci√≥n fueran v√°lidos y completos.
# **5. Modelo Final y Recomendaciones:
# 
# El modelo Ridge fue seleccionado como el modelo final debido a su capacidad para manejar la regularizaci√≥n, lo que es especialmente √∫til en contextos donde el riesgo de sobreajuste es alto. Aunque la diferencia en el rendimiento entre el modelo base y el modelo Ridge fue modesta, la regularizaci√≥n adicional del modelo Ridge proporciona una ventaja en t√©rminos de estabilidad y generalizaci√≥n.</p>
# </div>

# ## CONCLUSI√ìN GENERAL 

# <div class="alert alert-block alert-info">
#   <p>El proyecto ha logrado desarrollar un modelo de regresi√≥n robusto capaz de predecir la variable objetivo con un nivel de precisi√≥n razonable. La metodolog√≠a seguida, que incluy√≥ la limpieza exhaustiva de datos, la comparaci√≥n de modelos y la evaluaci√≥n rigurosa de su rendimiento, asegura que el modelo final es adecuado para los fines propuestos. El modelo Ridge, con su capacidad de regularizaci√≥n, ofrece un buen equilibrio entre precisi√≥n y estabilidad, lo que lo convierte en una opci√≥n recomendada para futuras aplicaciones.</p>
# </div>

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b>
#     
# Las conclusiones del proyecto est√°n **bien elaboradas** y proporcionan un resumen claro de las etapas clave del an√°lisis y del modelado. **Has logrado seleccionar un modelo adecuado** y justificaste su elecci√≥n bas√°ndote en las caracter√≠sticas de los datos, lo cual es **un punto fuerte** en tu trabajo. Adem√°s, las m√©tricas de evaluaci√≥n muestran que el modelo Ridge es **capaz de manejar la variabilidad de los datos con una precisi√≥n razonable**.
# 
# Para fortalecer a√∫n m√°s tus conclusiones, ser√≠a valioso que reflexionaras sobre **las posibles limitaciones del modelo Ridge**, como su sensibilidad a los outliers, y que propusieras maneras de mitigar estos desaf√≠os en futuros proyectos. Tambi√©n podr√≠as expandir sobre **c√≥mo los resultados obtenidos podr√≠an influir en las decisiones estrat√©gicas de la empresa**, especialmente en la retenci√≥n de clientes, lo que destacar√≠a la aplicabilidad pr√°ctica de tu trabajo.<
# 
# **Aprobado**. Has hecho un excelente trabajo, demostrando un s√≥lido entendimiento del an√°lisis de datos y del modelado predictivo. ¬°Sigue adelante con este mismo entusiasmo y dedicaci√≥n! üöÄüí™
# </div>
# 
